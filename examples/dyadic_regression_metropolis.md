Dyadic Regression with Metropolis
================

Dyadic regression is a regression analysis often used in social network
analysis to determine factors that may be associated with edge weight,
for example, age or sex. In this notebook we will use edge weight
posteriors from a previously-run edge weight model from binary data to
conduct a dyadic regression of edge weight against dyad type. In our toy
example, dyad type will be one of `lifeform-lifeform`, `lifeform-droid`,
and `droid-droid`. For this example we will be using a
Metropolis-Hastings sampler to maintain uncertainty over the data. The
sampler is still experimental so should be used with caution, but can
provide flexibility over the type of model being fitted. Alternatively,
an approximation of uncertainty over edge weights can be used instead,
and is shown in `dyadic_regression.Rmd`.

# Setup and Loading the edge weights

Before we start, we’ll need to load required libraries and the
metropolis sampler from the custom R file `sampler.R`.

``` r
source("../scripts/sampler.R")
```

We’ll load edge weight posteriors in from a previous run model using the
`readRDS()` function. These data were generated by the `ewm_binary.Rmd`
example in the Github repository.

``` r
data <- readRDS("../example_data/binary.RData")
df <- data$df
df_agg <- data$df_agg
logit_edge_samples <- data$logit_edge_samples
```

# Preparing the data

Now that the edge weights are loaded, we need to prepare the data for
fitting the dyadic regression model. This involves 1) preparing a
response matrix of edge weights describing the distribution of edge
weights for each dyad, and 2) building a predictor matrix indicating
which dyad type each dyad belongs to (1, 2, and 3 corresponding to ll,
ld, and dd), and which two nodes make up the dyad (1 through 8 in this
case).

``` r
predictor_matrix <- matrix(0, 28, 3)
colnames(predictor_matrix) <- c("dyad_type", "node_1_id", "node_2_id")
predictor_matrix[, 1] <- as.integer(df_agg$dyad_type)
predictor_matrix[, 2] <- df_agg$node_1_id
predictor_matrix[, 3] <- df_agg$node_2_id
predictor_matrix
```

    ##       dyad_type node_1_id node_2_id
    ##  [1,]         1         1         2
    ##  [2,]         1         1         3
    ##  [3,]         1         1         4
    ##  [4,]         2         1         5
    ##  [5,]         2         1         6
    ##  [6,]         2         1         7
    ##  [7,]         2         1         8
    ##  [8,]         1         2         3
    ##  [9,]         1         2         4
    ## [10,]         2         2         5
    ## [11,]         2         2         6
    ## [12,]         2         2         7
    ## [13,]         2         2         8
    ## [14,]         1         3         4
    ## [15,]         2         3         5
    ## [16,]         2         3         6
    ## [17,]         2         3         7
    ## [18,]         2         3         8
    ## [19,]         2         4         5
    ## [20,]         2         4         6
    ## [21,]         2         4         7
    ## [22,]         2         4         8
    ## [23,]         3         5         6
    ## [24,]         3         5         7
    ## [25,]         3         5         8
    ## [26,]         3         6         7
    ## [27,]         3         6         8
    ## [28,]         3         7         8

# Defining the model

Now everything else is in place, it’s time to define the model. As in
Stan, the model will be defined by its log-likelihood function, but
since we’re using a custom Metropolis sampler directly in R, the
log-likelihood function will need to be written directly in R. Writing
likelihood functions is beyond the scope of this tutorial, but a good
resource on the topic can be found here:
<https://www.ime.unicamp.br/~cnaber/optim_1.pdf>.

The dyadic regression model we’ll be using will predict the standardised
edge weight (Z-score) using a Gaussian family model where dyad type is
the main effect, and multi-membership terms are included as random
effects to account for non-independence between edges due to nodes.
Priors are set relatively narrow to improve model fit for the purposes
of this example, but in any real analysis they should be determined by
domain knowledge and predictive checks.

``` r
loglik_dyadreg <- function(params, Y, X, index) {
  ### Define parameters ###
  beta_dyadtype <- params[1:3]
  sigma <- exp(params[4]) # Exponential keeps underlying value unconstrained, which is much easier for the sampler.
  sigma_mm <- exp(params[5])
  mm <- params[6:13]
  
  ### Sample data according to index ###
  y <- Y[index %% dim(Y)[1] + 1, ]
  
  ### Define model ###
  
  target <- 0
  
  ## Linear predictor ##
  # y ~ normal(b_intercept + b_dyadtype + mm[i] + mm[j], sigma)
  target <- target + sum(dnorm(y, mean=beta_dyadtype[X[, 1]] + mm[X[, 2]] + mm[X[, 3]], sd=sigma, log=TRUE)) # Main model
  # b_dyadtype ~ normal(0, 0.5)
  target <- target + sum(dnorm(beta_dyadtype, mean=0, sd=1, log=TRUE))
  # sigma ~ exponential(1)
  target <- target + dexp(sigma, rate=1, log=TRUE)
  
  ## Node multimembership terms ##
  # mm ~ normal(0, sigma_mm)
  target <- target + sum(dnorm(mm, mean=0, sd=sigma_mm, log=TRUE))
  # sigma_mm ~ exponential(1)
  target <- target + dexp(sigma_mm, rate=1, log=TRUE)
  
  return(target)
}

# Create the `target` function that evaluates the log-likelihood on the dataset.
target <- function(params, index) loglik_dyadreg(params, logit_edge_samples, predictor_matrix, index)
```

We now have a function `target(params, index)` that gives the
log-likelihood of a set of parameters `params` given the data, for a
particular sample of the posterior edge weights, `index`. Let’s make
sure it works on an initial set of parameters all set to zero, for an
arbitrary index of the data. Note that the standard deviation parameters
are transformed by an exponential in the log-likelihood function, so the
sampler will treat them on the log-scale, meaning log(sigma) = 0 is
equivalent to sigma = 1.

``` r
target(rep(0, 13), 1)
```

    ## [1] -81.14834

The function has evaluated to a real number, so everything appears to be
working okay so far. Now we can use the function `metropolis` from
`sampler.R` to fit the model using the provided target function, an
initial set of parameters (again, all zeros), and some additional MCMC
options. Once the sampler has run, we will print out the top few rows of
the chains.

``` r
chain <- metropolis(target, rep(0, 13), iterations=200000, thin=100, refresh=10000)
```

    ## Chain: 1 | Iteration: 10000/202000 (Sampling)
    ## Chain: 1 | Iteration: 20000/202000 (Sampling)
    ## Chain: 1 | Iteration: 30000/202000 (Sampling)
    ## Chain: 1 | Iteration: 40000/202000 (Sampling)
    ## Chain: 1 | Iteration: 50000/202000 (Sampling)
    ## Chain: 1 | Iteration: 60000/202000 (Sampling)
    ## Chain: 1 | Iteration: 70000/202000 (Sampling)
    ## Chain: 1 | Iteration: 80000/202000 (Sampling)
    ## Chain: 1 | Iteration: 90000/202000 (Sampling)
    ## Chain: 1 | Iteration: 100000/202000 (Sampling)
    ## Chain: 1 | Iteration: 110000/202000 (Sampling)
    ## Chain: 1 | Iteration: 120000/202000 (Sampling)
    ## Chain: 1 | Iteration: 130000/202000 (Sampling)
    ## Chain: 1 | Iteration: 140000/202000 (Sampling)
    ## Chain: 1 | Iteration: 150000/202000 (Sampling)
    ## Chain: 1 | Iteration: 160000/202000 (Sampling)
    ## Chain: 1 | Iteration: 170000/202000 (Sampling)
    ## Chain: 1 | Iteration: 180000/202000 (Sampling)
    ## Chain: 1 | Iteration: 190000/202000 (Sampling)
    ## Chain: 1 | Iteration: 200000/202000 (Sampling)
    ## Acceptance Rate: 0.21969801980198

``` r
chain[, 4] <- exp(chain[, 4])
chain[, 5] <- exp(chain[, 5])
colnames(chain) <- c("b_ll", "b_ld", "b_dd", "sigma", "mm_sigma", sapply(1:8, function(i) paste0("mm_", i)))
head(chain)
```

    ##          b_ll       b_ld       b_dd     sigma  mm_sigma       mm_1        mm_2
    ## [1,] 1.673785  0.8278334 -1.6680155 1.0524879 0.6296111  0.1666152 -0.38024317
    ## [2,] 2.018373  0.4894471 -1.6749821 1.0985291 0.6348117  0.4003186 -0.90804756
    ## [3,] 1.473969 -0.4106009 -2.1297789 1.1482064 0.4230453 -0.4315277  0.20740738
    ## [4,] 1.215656 -0.2069496 -0.8491416 1.0190971 1.2161284  0.3134605  0.46434872
    ## [5,] 1.790269  0.2236366 -0.7895502 0.6444986 0.5728979  0.3749957 -0.08978315
    ## [6,] 1.251120 -0.3876298 -0.9464064 0.9665847 0.5141623 -0.3132845 -0.34483611
    ##            mm_3       mm_4        mm_5       mm_6        mm_7       mm_8
    ## [1,] -0.6104652  0.6265317 -0.14598755 0.31868291  0.14791456 -1.8683486
    ## [2,]  0.6778173  1.0668901 -0.12405856 0.78011212  0.38990549 -0.4682307
    ## [3,]  1.1742557 -0.4359783  0.07874369 0.32016961  0.09797093  0.1428238
    ## [4,]  0.5544024  1.0362722 -0.03169844 0.78511401 -1.06585478 -1.7325970
    ## [5,]  0.1357228  0.6876859 -0.03440577 0.09025081 -0.65663705 -1.1522520
    ## [6,]  0.5072872  1.2167891 -0.60402039 0.49172479  0.12443749 -0.5311777

The acceptance rate is around 0.23, which is the target acceptance rate
for this sampler. Deviances from 0.23 could indicate sampling issues,
but the converse is not true, so acceptance rate isn’t an ideal
diagnostic tool. Instead it’s best to inspect the traceplots, which can
be done using the following code:

``` r
par(mfrow=c(4, 4), mar=c(1,1,1,1))
for (i in 1:13) {
  plot(chain[, i], type="l")
}
```

![](dyadic_regression_metropolis_files/figure-gfm/unnamed-chunk-7-1.png)<!-- -->
**Note: In our runs of the code, these traces usually look good. But the
stochastic nature of MCMC and the experimental sampler mean that
sometimes the chains may not behave well. If the chains in this notebook
have not converged, this is likely an artefact of this stochasticity.**

At this point it’s a good idea to do some diagnostic checks, such as
predictive checks or residual plots. These are covered separately in the
Github repository, so in-depth diagnostic checks aren’t shown here, but
should always be carried out.

# Posterior predictive checks

We will run a brief diagnostic check by comparing the density of
expected edge weights (draws of which are shown in black) against the
density of predicted edge weights from the regression model (draws of
which are shown in blue).

``` r
plot(density(logit_edge_samples[1, ]), col=rgb(0, 0, 0, 0.25), ylim=c(0, 0.8), main="Posterior predictive density", xlab="Logit edge weight")
for (i in 1:100) {
  j <- sample(1:2000, 1)
  lines(density(logit_edge_samples[j, ]), col=rgb(0, 0, 0, 0.25))
  lines(density(
    rnorm(28, mean=chain[j, 1:3][predictor_matrix[, 1]] + chain[j, 6:13][predictor_matrix[, 2]] + chain[j, 6:13][predictor_matrix[, 3]], sd=chain[j, 4])
  ),
  col=rgb(0, 0, 1, 0.25))
}
```

![](dyadic_regression_metropolis_files/figure-gfm/unnamed-chunk-8-1.png)<!-- -->
Almost all of the expected (black) densities fall within the range
expected from the predicted (blue) densities. The distribution of edge
weights appears to have been captured well by the regression model.
There are many other types of diagnostic check that could be carried
out, but we won’t go into detail here. See the github repository page
for more information.

# Interpreting the model

Assuming we’ve now carried out any diagnostics we think are appropriate,
it’s finally time to answer the scientific questions that led us to
conduct the analysis. We can start off by calculating the 95% credible
intervals of the model parameters. This can be done using the following
code:

``` r
summary_matrix <- t(apply(chain, 2, function(x) quantile(x, probs=c(0.5, 0.025, 0.975))))
summary_matrix <- round(summary_matrix, 2)
summary_matrix
```

    ##            50%  2.5% 97.5%
    ## b_ll      1.49 -0.27  2.84
    ## b_ld      0.06 -0.90  0.98
    ## b_dd     -1.40 -2.66  0.28
    ## sigma     1.06  0.74  1.53
    ## mm_sigma  0.59  0.14  1.56
    ## mm_1      0.02 -0.83  1.08
    ## mm_2      0.10 -0.72  1.20
    ## mm_3      0.42 -0.36  1.77
    ## mm_4      0.44 -0.39  1.80
    ## mm_5     -0.26 -1.42  0.59
    ## mm_6      0.33 -0.51  1.32
    ## mm_7     -0.24 -1.37  0.56
    ## mm_8     -0.78 -2.23  0.12

At this point it becomes clear that the regression we’ve conducted is
not exactly the same as what might be expected from standard frequentist
regressions, where categories are interpreted relative to a reference
category. Instead, a parameter is estimated for each category, and we
can use *contrasts* to calculate the magnitude of differences between
categories of interest. Contrasts are easily calculated as the statistic
of interest from the posteriors of the model. Namely, if we’re interest
in whether lifeform-lifeform edges are stronger than lifeform-droid
edges, we simply compute the difference in posteriors between `b_ll` and
`b_ld`. This can be done using the following code:

``` r
b_diff <- chain[, "b_ll"] - chain[, "b_dd"]
plot(density(b_diff), main="Posterior difference between dyad types")
abline(v=0, lty=2)
```

![](dyadic_regression_metropolis_files/figure-gfm/unnamed-chunk-10-1.png)<!-- -->

``` r
b_diff_summary <- round(quantile(b_diff, probs=c(0.5, 0.025, 0.975)), 2)
b_diff_summary
```

    ##   50%  2.5% 97.5% 
    ##  2.84 -0.08  4.86

This gives us an estimate that lifeform-lifeform edge weights are
generally around \~2.9 logit-scale units stronger than lifeform-droid
edges, with a 95% credible interval of around \~(0.3, 4.8).

# Conclusion

This notebook has given a brief overview of how to fit and interpret a
dyadic regression model using the Metropolis-Hastings sampler in BISoN.
We also have a guide on how to conduct the same type of analysis in Stan
(examples/dyadic_regression.Rmd) using a Gaussian approximation of edge
weights, which should yield similar results and may be less prone to
model fitting issues, at the cost of being less flexible for some types
of model.
